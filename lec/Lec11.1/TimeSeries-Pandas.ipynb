{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Time Series in Pandas \n",
    "\n",
    "https://aeturrell.github.io/coding-for-economists/time-series.html\n",
    "\n",
    "https://aeturrell.github.io/coding-for-economists/time-intro.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Some datetime and Pandas datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from rich import inspect\n",
    "except ImportError:\n",
    "    %pip install rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "print(now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the object using the rich library\n",
    "inspect(now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDOS = datetime(2024, 4, 25)\n",
    "print(LDOS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now > LDOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "econ_grad_string = \"15 May in 2024\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.strptime(econ_grad_string, \"%d %B in %Y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "econ_date = datetime.strptime(econ_grad_string, \"%d %B in %Y\")\n",
    "econ_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"Economics Graduation will be at \")\n",
    "econ_date.strftime(\"%A, %B %d, %Y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_left = econ_date - now\n",
    "days_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Only {days_left.days} days left until graduation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect(days_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a pandas now and LDOS\n",
    "import pandas as pd\n",
    "# make a pandas now and LDOS\n",
    "now_pd = pd.to_datetime(now)\n",
    "LDOS_pd = pd.to_datetime(LDOS)\n",
    "now_pd, LDOS_pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pandas now in pacific time   \n",
    "now_pd_pacific = now_pd.tz_localize('US/Pacific')\n",
    "now_pd_pacific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now convert to singapore time\n",
    "now_pd_singapore = now_pd_pacific.tz_convert('Asia/Singapore')\n",
    "now_pd_singapore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleepy = now_pd_singapore - now_pd_pacific\n",
    "sleepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets demo with Econ graduation Date\n",
    "econ_date_pd = pd.to_datetime(econ_date)\n",
    "econ_date_pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shft the date formwards by 1 day\n",
    "get_ready= econ_date_pd - pd.Timedelta(days=1)\n",
    "get_ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacation = econ_date_pd + pd.Timedelta(days=7)\n",
    "vacation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Get_job = econ_date_pd + pd.Timedelta(days=30)\n",
    "Get_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Part 2 - Time Series in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s see how to turn data that has been read in with a non-datetime type into a vector of datetimes. This happens all the time in practice. We’ll read in some data on job vacancies for information and communication jobs, ONS code UNEM-JP9P, and then try to wrangle the given “date” column into a pandas datetime column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset from URL\n",
    "url = \"https://api.ons.gov.uk/timeseries/JP9P/dataset/UNEM/data\"\n",
    "# Get the data from the ONS API:\n",
    "df = pd.DataFrame(pd.json_normalize(requests.get(url).json()[\"months\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"value\"] = pd.to_numeric(df[\"value\"])\n",
    "df = df[[\"date\", \"value\"]]\n",
    "df = df.rename(columns={\"value\": \"Vacancies (ICT), thousands\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to local  for use in other notebooks\n",
    "df.to_csv(\"ONS_vacancies.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ONS_vacancies.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"date\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "An aside on different types of date formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df = pd.DataFrame({\"date\": [\"1, '19, 22\", \"1, '19, 23\"], \"values\": [\"1\", \"2\"]})\n",
    "small_df[\"date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(small_df[\"date\"], format=\"%m, '%y, %d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"date\"] = df[\"date\"] + pd.offsets.MonthEnd()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"Using `dt.day_name()`\")\n",
    "print(df[\"date\"].dt.day_name().head())\n",
    "print(\"Using `dt.isocalendar()`\")\n",
    "print(df[\"date\"].dt.isocalendar().head())\n",
    "print(\"Using `dt.month`\")\n",
    "print(df[\"date\"].dt.month.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(\"date\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.asfreq(\"M\")\n",
    "df.index[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remake the dataset as an annual dataset\n",
    "#using the mean across months\n",
    "\n",
    "df.resample(\"A\").mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.resample(\"5A\").agg([\"mean\", \"std\"]).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.resample(\"D\").asfreq()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.resample(\"D\").interpolate(method=\"linear\", limit_direction=\"forward\", limit=3)[:6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Moving Average\n",
    "df.rolling(2).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponetially Weighted Moving Average \n",
    "df.ewm(alpha=0.2).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead = 12\n",
    "lag = 3\n",
    "orig_series_name = df.columns[0]\n",
    "df[f\"lead ({lead} months)\"] = df[orig_series_name].shift(-lead)\n",
    "df[f\"lag ({lag} months)\"] = df[orig_series_name].shift(lag)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[100:300, :].plot();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics import tsaplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = tsaplots.plot_acf(df[\"Vacancies (ICT), thousands\"], lags=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = tsaplots.plot_pacf(df[\"Vacancies (ICT), thousands\"], lags=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding examples from Pandas Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URl2 = \"https://raw.githubusercontent.com/pandas-dev/pandas/main/doc/data/air_quality_no2_long.csv\"\n",
    "air_quality = pd.read_csv(URl2)\n",
    "air_quality = air_quality.rename(columns={\"date.utc\": \"datetime\"})\n",
    "\n",
    "air_quality.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality.city.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what type of data is in the datetime column\n",
    "air_quality[\"datetime\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality[\"datetime\"] = pd.to_datetime(air_quality[\"datetime\"])\n",
    "air_quality[\"datetime\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can do it directly in the read_csv function\n",
    "air_quality2 = pd.read_csv(URl2, parse_dates=[\"date.utc\"])\n",
    "air_quality2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality2[\"date.utc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality[\"datetime\"].min(), air_quality[\"datetime\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality[\"datetime\"].max() - air_quality[\"datetime\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality[\"month\"] = air_quality[\"datetime\"].dt.month\n",
    "air_quality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pandas, the .dt accessor is used with Series objects containing datetime-like data. It provides access to a wide range of properties and methods to perform operations on the data as datetime objects. When you have a Series of datetime objects, using .dt allows you to extract information like the year, month, day, hour, and minute, or even perform more complex manipulations like time zone conversions.\n",
    "\n",
    "Here's a brief overview of some of the properties and methods available via the .dt accessor:\n",
    "\n",
    "Properties\n",
    " - **date:** Returns the date part of each datetime.\n",
    "- **time:** Returns the time part of each datetime.\n",
    "- **year:** Returns the year of each datetime.\n",
    "- **month:** Returns the month of each datetime.\n",
    "- **day:** Returns the day of each datetime.\n",
    "- **hour:** Returns the hour of each datetime.\n",
    "- **minute:** Returns the minute of each datetime.\n",
    "- **second:** Returns the second of each datetime.\n",
    "- **microsecond:** Returns the microsecond of each datetime.\n",
    "- **nanosecond:** Returns the nanosecond of each datetime.\n",
    "- **dayofweek:** Returns the day of the week (Monday=0, Sunday=6).\n",
    "- **dayofyear:** Returns the ordinal day of the year.\n",
    "- **weekofyear:** Returns the week ordinal of the year.\n",
    "- **quarter:** Returns the quarter of the date.\n",
    "- **is_month_start:** Returns True for elements that are the first day of the month.\n",
    "- **is_month_end:** Returns True for elements that are the last day of the month.\n",
    "- **is_quarter_start:** Returns True for elements that are the first day of the quarter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis**\n",
    "Lets look at the average reading for each sensor for each weekday using `groupby`\n",
    "To group on weekdays, we use the datetime property weekday (with Monday=0 and Sunday=6) of pandas Timestamp, which is also accessible by the dt accessor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality.groupby(\n",
    "    [air_quality[\"datetime\"].dt.weekday, \"location\"])[\"value\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Graph**  Let's plot the hourly NO2 across allstattions using the average reading for each hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "air_quality.groupby(air_quality[\"datetime\"].dt.hour)[\"value\"].mean().plot(\n",
    "    kind='bar', rot=0, ax=axs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Pivot to make a table that has columns by Sensor Location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_2 = air_quality.pivot(index=\"datetime\", columns=\"location\", values=\"value\")\n",
    "no_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset of time with the raw data plotted\n",
    "no_2[\"2019-05-20\":\"2019-05-21\"].plot(subplots=False, figsize=(12, 16));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_max = no_2.resample(\"M\").max()\n",
    "monthly_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_max = no_2.resample(\"W\").max()\n",
    "weekly_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daily average\n",
    "no_2.resample(\"D\").mean().plot(style=\"-o\", figsize=(10, 5));\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
