{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Folktables - A replacement for Adult ACS dataset \n",
    "### and an easy way to import ACS data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code from Folktables Repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: \n",
    " - [Retiring Adult](https://openreview.net/forum?id=bYi_2708mKK)\n",
    " - [Folktables on Github](https://github.com/socialfoundations/folktables)\n",
    " - [Folktable Datasheet](https://github.com/socialfoundations/folktables/blob/main/datasheet.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import folktables\n",
    "except ImportError:\n",
    "    !pip install folktables\n",
    "    import folktables\n",
    "    from folktables import ACSDataSource, ACSEmployment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arguments for importing data from folktables \n",
    "- survey_year: str, optional\n",
    " --    The year of the survey data to download. Default is '2018'.\n",
    " -  horizon: str, optional\n",
    " -- The time horizon of the survey data to download. Default is '1-Year'.\n",
    " -  survey: str, optional\n",
    "-- The type of survey data to download. Default is 'person'.\n",
    "- states: list, optional\n",
    "-- A list of state abbreviations to download data for. Default is None.\n",
    "-- If None, data for all states will be downloaded.\n",
    "- download: bool, optional\n",
    "-- Whether to download the data. Default is True. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Alabama, 2018, one year estimates, person survey, Employment status\n",
    "\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[\"AL\"], download=True)\n",
    "features, label, group = ACSEmployment.df_to_numpy(acs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    features, label, group, test_size=0.2, random_state=0)\n",
    "\n",
    "###### Your favorite learning algorithm here #####\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "white_tpr = np.mean(yhat[(y_test == 1) & (group_test == 1)])\n",
    "black_tpr = np.mean(yhat[(y_test == 1) & (group_test == 2)])\n",
    "\n",
    "# Equality of opportunity violation: 0.0871\n",
    "diff_tpr = white_tpr - black_tpr\n",
    "print('The white True Positive Rate is ',white_tpr)\n",
    "print('The black True Positive Rate is ',black_tpr)\n",
    "print('The difference in True Positive Rates is ',diff_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# can we print a confusion matrix for each  group?\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "white_confusion_matrix = confusion_matrix(y_test[(group_test == 1)], yhat[(group_test == 1)])\n",
    "print(\"Confusion Matrix for the White Group:\")\n",
    "print(white_confusion_matrix)\n",
    "\n",
    "black_confusion_matrix = confusion_matrix(y_test[(group_test == 2)], yhat[(group_test == 2)])\n",
    "print(\"Confusion Matrix for the Black Group:\")\n",
    "print(black_confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def print_confusion_matrix_percentages(y_true, y_pred, group_name, decimals=2):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_percentage = cm / cm.sum(axis=1, keepdims=True) * 100  # Normalize by row sums\n",
    "    cm_rounded = np.round(cm_percentage, decimals)  # Round the percentages\n",
    "    print(f\"Confusion Matrix for the {group_name} Group (Percentages):\")\n",
    "    print(cm_rounded)\n",
    "    print(\"Labels: [Negative, Positive]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "print_confusion_matrix_percentages(y_test[(group_test == 1)], yhat[(group_test == 1)], \"White\")\n",
    "\n",
    "print_confusion_matrix_percentages(y_test[(group_test == 2)], yhat[(group_test == 2)], \"Black\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "acs_tx = data_source.get_data(states=[\"TX\"], download=True)\n",
    "tx_features, tx_label, tx_group = ACSEmployment.df_to_numpy(acs_tx)\n",
    "\n",
    "features, label, group = ACSEmployment.df_to_numpy(acs_tx)\n",
    "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    tx_features, tx_label, tx_group, test_size=0.2, random_state=0)\n",
    "\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "white_tpr = np.mean(yhat[(y_test == 1) & (group_test == 1)])\n",
    "black_tpr = np.mean(yhat[(y_test == 1) & (group_test == 2)])\n",
    "\n",
    "# Equality of opportunity violation: 0.0397\n",
    "white_tpr - black_tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from folktables import ACSDataSource, ACSIncome\n",
    "\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "ca_data = data_source.get_data(states=[\"CA\"], download=True)\n",
    "mi_data = data_source.get_data(states=[\"MI\"], download=True)\n",
    "ca_features, ca_labels, _ = ACSIncome.df_to_numpy(ca_data)\n",
    "mi_features, mi_labels, _ = ACSIncome.df_to_numpy(mi_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Standardize the features and train the model\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Train on CA data\n",
    "model.fit(ca_features, ca_labels)\n",
    "\n",
    "# Test on MI data\n",
    "model.score(mi_features, mi_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Comparing Different Years \n",
    "### Train on 2014 and ruun on succeeding Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from folktables import ACSDataSource, ACSPublicCoverage\n",
    "\n",
    "# Download 2014 data\n",
    "data_source = ACSDataSource(survey_year=2014, horizon='1-Year', survey='person')\n",
    "acs_data14 = data_source.get_data(states=[\"CA\"], download=True)\n",
    "features14, labels14, _ = ACSPublicCoverage.df_to_numpy(acs_data14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Train model on 2014 data\n",
    "# Plug-in your method for tabular datasets\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "model.fit(features14, labels14)\n",
    "\n",
    "# Evaluate model on 2015-2018 data\n",
    "\n",
    "accuracies = []\n",
    "for year in [2015, 2016, 2017, 2018]:\n",
    "    data_source = ACSDataSource(survey_year=year, horizon='1-Year', survey='person')\n",
    "    acs_data = data_source.get_data(states=[\"CA\"], download=True)\n",
    "    features, labels, _ = ACSPublicCoverage.df_to_numpy(acs_data)\n",
    "    accuracies.append(model.score(features, labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up a moel with new parameters\n",
    " - Decide on Features\n",
    " - Change income threshold to 25K\n",
    " - groups to compare are gender\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "ACSIncomeNew = folktables.BasicProblem(\n",
    "    features=[\n",
    "        'COW',\n",
    "        'SCHL',\n",
    "        'MAR',\n",
    "        'OCCP',\n",
    "        'POBP',\n",
    "        'RELP',\n",
    "        'WKHP',\n",
    "        'SEX',\n",
    "        'RAC1P',\n",
    "    ],\n",
    "    target='PINCP',\n",
    "    target_transform=lambda x: x > 25000,    \n",
    "    group='SEX',\n",
    "    preprocess=folktables.adult_filter,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this new model on 2018 data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Download 2018 data\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[\"CA\"], download=True)\n",
    "features, labels, groups = ACSIncomeNew.df_to_numpy(acs_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Model training\n",
    "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    features, labels, groups, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Standardize the features and train the model\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "model.fit(X_train, y_train)\n",
    "# Evaluate the model\n",
    "model.score(X_test, y_test)\n",
    "# Evaluate the model for each group\n",
    "accuracies = []\n",
    "for group in np.unique(groups):\n",
    "    mask = groups == group\n",
    "    accuracies.append(model.score(features[mask], labels[mask]))\n",
    "print(accuracies)\n",
    "\n",
    "Difference = accuracies[0] - accuracies[1]\n",
    "Difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
