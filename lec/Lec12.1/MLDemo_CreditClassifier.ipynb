{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01638e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c628b6d0",
   "metadata": {},
   "source": [
    "# Machine Learning Models\n",
    "---\n",
    "\n",
    "In this lab, we'll cover a few machine learning models to make classification predictions. We'll start with the k-nearest neighbors classifier, which you should have seen in Data 8, then move to a couple more models. Note that the models that we work with are solely for classification. Numerical predictions will require different [models](https://scikit-learn.org/stable/supervised_learning.html).\n",
    "\n",
    "1. [K-Nearest Neighbors](#knn)\n",
    "2. [Decision Trees](#decisiontree)\n",
    "3. [Random Forest](#randforest)\n",
    "4. [Support Vector Classification](#svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2af4af",
   "metadata": {},
   "source": [
    "## Data Cleaning & Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf73431",
   "metadata": {},
   "source": [
    "This notebook will use credit card default data from Taiwan. You can find the original data and a description of the data [here](https://archive.ics.uci.edu/dataset/350/default+of+credit+card+clients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4972bca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"credit_card_defaults.xls\",  header=1, dtype=np.int64)\n",
    "data.head(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b518b5da",
   "metadata": {},
   "source": [
    "### Cleaning the Dataset\n",
    "\n",
    "You might have noted that the first column and the first row of our original data look a little funky. In the next few cells, we remedy this by dropping the column \"Unnamed: 0\" and replacing the current column names with the values in the first row.\n",
    "\n",
    "First, we drop the first column, which was the original index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d2657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = data.drop(data.columns[0], axis=1)\n",
    "clean.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649ae8c7",
   "metadata": {},
   "source": [
    "Then, we can collect all of the variable names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b09bfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = clean.iloc[0].to_dict()\n",
    "print(\"Some Keys: \", list(variables.keys())[:5])\n",
    "print(\"Some Values: \", list(variables.values())[:5])\n",
    "variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562efc67",
   "metadata": {},
   "source": [
    "You can also assign the explanatory columns directly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7469fc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(model_data.columns)\n",
    "\n",
    "X = model_data[['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE']].astype(int)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f12c0cf",
   "metadata": {},
   "source": [
    "Finally, we relabel our column names with the variables that were originally in the first row of our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a06b6f",
   "metadata": {},
   "source": [
    "### Working with a Subset of Our Data\n",
    "\n",
    "Our dataset looks a little cleaner now. Next, take a look at how many entries are in our dataset. There are a large number of entries, which is great! However, DataHub can only do so much computation, so we'll take a random sample of 10,000 entries for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a36da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the number of entries in our dataset\n",
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d3389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a sample of our data\n",
    "model_data = clean.sample(n=10000, random_state=42)\n",
    "model_data.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e7e56b",
   "metadata": {},
   "source": [
    "### Preparing the Data for an ML Model\n",
    "\n",
    "Finally, the last thing we do is split our data into a training and test set. The training set will help us make our model, and the test set will evaluate how well our model works. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc3a841",
   "metadata": {},
   "source": [
    "Next, we'll split our data into `X` and `y` variables. Our `X` variable will be a dataset full of every variable but \"payment next month\", the last column in our table. The `y` variable will have the \"payment next month\" variable.\n",
    "\n",
    "**Note:** The following lines of code have `astype(int)` at the end. Our data is not originally inputted as integers, so we need to make sure that they are!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce5dc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = model_data[list(variables.keys())[0:-1]].astype(int) \n",
    "y = model_data[list(variables.keys())[-1]].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0915ae15",
   "metadata": {},
   "source": [
    "Now that we have our `X` and `y` variables, we can split them into training and test sets. The next cell does a random 80/20 split of our data into these two sets. Notice that there are four outputs from `train_test_split`, which we assign to `X_train`, `X_test`, `y_train`, and `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47ed80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d82885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check that we split the train set\n",
    "print(\"X train shape: \", X_train.shape)\n",
    "print(\"y train shape: \", y_train.shape)\n",
    "print(\"X test shape: \", X_test.shape)\n",
    "print(\"y test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4481ed7",
   "metadata": {},
   "source": [
    "## 1. K-Nearest Neighbors Classifier <a id='knn'></a>\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e0e74e",
   "metadata": {},
   "source": [
    "### Specifying Hyperparameters\n",
    "\n",
    "Let's start by creating a k-nearest neighbors classifier where $k=3$. We'll use the `KNeighborsClassifier` model from the scikit-learn library, which has a multitude of models you could use.\n",
    "\n",
    "Fill in the first blank to specify your hyperparameter (in this case, the value of `k`). Then, use this [page](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) to create the classifier. Please reference this page for the remainder of this section. You may find the \"Examples\" section helpful, but please also read through the \"Parameters\", \"Attributes\", and \"Methods\" sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf98703",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5ca4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3 \n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=k) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb5f24b",
   "metadata": {},
   "source": [
    "### Training the Model on Your Data\n",
    "\n",
    "Note that our `knn` model has not yet \"trained\" on any data, as we have not given it any data to train on.\n",
    "\n",
    "Fit our model to the data we would like to train on. Your code should make use of your `X_train` dataset and your `y_train` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d742fd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4057f3",
   "metadata": {},
   "source": [
    "### Making Predictions\n",
    "\n",
    "After running your cell, you should see a blue box with \"KNeighborsClassifer\" on it. This indicates that our computer has prepared a model based on our specifications (ie. hyperparameters) and trained it. In other words, our model is now ready to make predictions!\n",
    "\n",
    "In this section, let's make predictions for our test set. Refer back to the documentation provided earlier.\n",
    "\n",
    "Your cell will create a light red box with an error message, but feel free to ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4540e9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0edbfdf",
   "metadata": {},
   "source": [
    "### Calculating Accuracy\n",
    "\n",
    "Now that we've made predictions for our test set, we should calculate the accuracy of our model. Take a look at the documentation for `accuracy_score` [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html). Use this function to calculate the accuracy score, and recall that accuracy is computed as follows.\n",
    "\n",
    "$$accuracy = \\frac{\\#\\:of\\:correct\\:predictions}{\\#\\:of\\:predictions}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d834c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4949bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a3d879",
   "metadata": {},
   "source": [
    "### Creating a Confusion Matrix\n",
    "\n",
    "Accuracy isn't the only metric to measure how well our model works. We can also evaluate our model by looking at a confusion matrix. Again, take a look at the relevant scikit-learn documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) and create a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69de7538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe9c21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print confusion matrix\n",
    "confusion_matrix_knn = confusion_matrix(y_test, y_pred) # SOLUTION\n",
    "print(confusion_matrix_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bac002",
   "metadata": {},
   "source": [
    "## 2. Decision Tree Classifier <a id='decisiontree'></a>\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6b560c",
   "metadata": {},
   "source": [
    "### Specifying Hyperparameters\n",
    "\n",
    "Now let's make a decision tree classifier! We imported another scikit-learn model (`DecisionTreeClassifier`) for you below. See this [page](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) for the official documentation and reference it for the remainder of this section.\n",
    "\n",
    "Create a `DecisionTreeClassifier` with a maximum depth of 5 and ensure that it does _not_ split on any nodes with 3 datapoints or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea4056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4215d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the hyperparameter(s) & train the model\n",
    "max_depth = 5 \n",
    "min_split = 4 \n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_split) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f89559",
   "metadata": {},
   "source": [
    "### Training the Model & Making Predictions\n",
    "\n",
    "Then, fit the model to your data. This should be similar to what you wrote for your `KNeighborsClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff711616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model to our data\n",
    "tree.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0e76c0",
   "metadata": {},
   "source": [
    "Once again, you should see a blue box with \"DecisionTreeClassifier\" written on it. Make some predictions using this model, and assign those predictions to the variable `y_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff72e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred = tree.predict(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20916021",
   "metadata": {},
   "source": [
    "### Measuring Goodness\n",
    "\n",
    "Finally, let's measure the goodness of our model. Calculate and print the accuracy of our model, then create and print a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4ee88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred) \n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf032619",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c34205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print confusion matrix\n",
    "confusion_matrix_tree = confusion_matrix(y_test, y_pred) \n",
    "print(confusion_matrix_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ec34e4",
   "metadata": {},
   "source": [
    "# Print the Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06322ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(tree, filled=True, feature_names=list(variables.values())[0:-1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a64c5f",
   "metadata": {},
   "source": [
    "## 3. Random Forest <a id='randforest'></a>\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eb6165",
   "metadata": {},
   "source": [
    "Next, let's work with a random forest. Recall that a random forest is composed of _multiple_ decision trees that split nodes on different variables. When making predictions, it has each decision tree make its own prediction and then outputs the majority class as its final prediction.\n",
    "\n",
    "See this [page](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) for the official documentation of scikit-learn's `RandomForestClassifier`. We'll repeat the process above by ...\n",
    "\n",
    "1. Specifying the Hyperparameters\n",
    "\n",
    "2. Training the Model & Making Predictions\n",
    "\n",
    "3. Measuring Goodness\n",
    "\n",
    "Specify a maximum depth of 5, split on nodes with only 4 or more values, use 10 decision trees, and only consider 1 feature when splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1629c2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9239c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the hyperparameter(s) & train the model\n",
    "max_depth = 5 \n",
    "min_split = 4 \n",
    "num_estimators = 10 \n",
    "max_fts = 1 \n",
    "\n",
    "forest = RandomForestClassifier(max_depth=max_depth, n_estimators=num_estimators, max_features=max_fts) # SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deaa1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model to our data\n",
    "forest.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db5010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7825a45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred) \n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0342d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print confusion matrix\n",
    "confusion_matrix_forest = confusion_matrix(y_test, y_pred) \n",
    "print(confusion_matrix_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40d77d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print tree    \n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(forest.estimators_[0], filled=True, feature_names=list(variables.values())[0:-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f18cd8a",
   "metadata": {},
   "source": [
    "## 4. Support Vector Classification <a id='svc'></a>\n",
    "---\n",
    "Lastly, we'll work with support vector classification. Reference this [page](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) for the official documentation and repeat the steps above.\n",
    "\n",
    "Make your regularization hyperparameter 1, then try out different values.\n",
    "\n",
    "TODO make more complicated, clarify hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01678284",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c6f4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the hyperparameter(s) & train the model\n",
    "reg_param = 5\n",
    "\n",
    "svc = SVC(C=reg_param) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9029ccbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model to our data\n",
    "svc.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323aa226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred = svc.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7300267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred) \n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b89335f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print confusion matrix\n",
    "confusion_matrix_forest = confusion_matrix(y_test, y_pred) \n",
    "print(confusion_matrix_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79eed6d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bfd0b9c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
